{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d913eb8a",
   "metadata": {},
   "source": [
    "# Wedge Task 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06e8c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "import io\n",
    "\n",
    "# Do our imports for part 2 of uploading\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ffc59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These first two values will be different on your machine. \n",
    "service_path = \"c:\\\\Users\\\\logan\\\\DataScience\\\\\"\n",
    "service_file = 'beskoonlettuce-327919-af8cb2931ac8.json' # this is your authentication information  \n",
    "gbq_proj_id = 'beskoonlettuce-327919'  # change this to your project_id\n",
    "gbq_dataset_id = 'wedge_transactions' # and change this to your data set ID\n",
    "\n",
    "private_key =service_path + service_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d385b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(service_path + service_file)\n",
    "\n",
    "# And create a client to talk to GBQ\n",
    "client = bigquery.Client(credentials = credentials, project=gbq_proj_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c2e069",
   "metadata": {},
   "source": [
    "The code listed below became my final approach for how to upload files, via Google Cloud Storage.\n",
    "\n",
    "The first step involved uploading all the csv files to GSC through the UI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec995a6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transArchive_201004_201006_clean.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_name = os.listdir(\"WedgeFiles_Clean/clean-files/\")\n",
    "print(file_name[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4295c1d1",
   "metadata": {},
   "source": [
    "## Batch Loading begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f13b9276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transArchive_201701_clean\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Now we want to create our table.\n",
    "#NOTE: change item of file_name for each file\n",
    "current_file = file_name[53]\n",
    "my_table = Path(current_file).stem\n",
    "print(my_table)\n",
    "table_full_name = \".\".join([gbq_proj_id,gbq_dataset_id,my_table])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cfd07e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tbl_exists(client, table_ref):\n",
    "    from google.cloud.exceptions import NotFound\n",
    "    try:\n",
    "        client.get_table(table_ref)\n",
    "        return True\n",
    "    except NotFound:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8324972",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not tbl_exists(client, table_full_name) :\n",
    "    table_ref = client.create_table(\n",
    "        table = table_full_name\n",
    "    )\n",
    "else :\n",
    "    table_ref = client.get_table(table_full_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f87ff",
   "metadata": {},
   "source": [
    "Now we have an empty table. The code chunk below is schema to be imported.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "804f8e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table transArchive_201701_clean contains 0 columns\n"
     ]
    }
   ],
   "source": [
    "table = client.get_table(table_ref)\n",
    "print(\"Table {} contains {} columns\".format(table_ref.table_id,len(table.schema)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca807d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND\n",
    "job_config.schema_update_options = [\n",
    "    bigquery.SchemaUpdateOption.ALLOW_FIELD_ADDITION # This allows us to modify the table. \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c2bed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_config.schema = [\n",
    "    bigquery.SchemaField(\"datetime\", \"TIMESTAMP\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"register_no\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"emp_no\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_no\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"upc\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"description\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_type\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_subtype\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_status\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"department\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"quantity\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Scale\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"cost\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"unitPrice\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"total\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"regPrice\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"altPrice\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"tax\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"taxexempt\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"foodstamp\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"wicable\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"discount\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"memDiscount\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"discountable\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"discounttype\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"voided\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"percentDiscount\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"ItemQtty\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"volDiscType\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"volume\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"VolSpecial\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"mixMatch\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"matched\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"memType\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"staff\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"numflag\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"itemstatus\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"tenderstatus\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"charflag\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"varflag\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"batchHeaderID\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"local\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"organic\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"display\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"receipt\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"card_no\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"store\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"branch\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"match_id\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_id\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "]\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "job_config.skip_leading_rows = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00c01dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://lettucewedge_bucket/clean-files/transArchive_201701_clean.csv\n"
     ]
    }
   ],
   "source": [
    "#generate correct URI\n",
    "uri = \"gs://lettucewedge_bucket/clean-files/\" + current_file\n",
    "print(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6d0e1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 936740 rows into wedge_example:transArchive_201701_clean.\n",
      "Table transArchive_201701_clean now contains 50 columns.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_job = client.load_table_from_uri(\n",
    "    uri, table, job_config=job_config\n",
    ") #Make API request\n",
    "\n",
    "load_job.result()  # Waits for table load to complete.\n",
    "print(\n",
    "        \"Loaded {} rows into {}:{}.\".format(\n",
    "            load_job.output_rows, 'wedge_example', table_ref.table_id\n",
    "    )\n",
    ")\n",
    "\n",
    "# Checks the updated length of the schema\n",
    "table = client.get_table(table)\n",
    "print(\"Table {} now contains {} columns.\".format(table_ref.table_id, len(table.schema)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214af88c",
   "metadata": {},
   "source": [
    "Need to go back to batch loading to complete all uploads. After 53, finished!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
